{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Objectives\n",
    "\n",
    "In this workshop, we will learn the basics on the principals of Spark by being hands-on.\n",
    "\n",
    "We will learn what Apache Spark is and run some transformations and actions (low level APIs).<br> \n",
    "We learn how to wrangle data with Spark and what the difference of 'RDDs vs DataFrames and Datasets' is.\n",
    "\n",
    "The course ends with an exercise. You need to replace 'code gaps' in a notebook to make the notebook work.\n",
    "\n",
    "Spark offers very good libraries and capabilities for advanced data analytics and machine learning (ML). If you are already familiar with ML concepts and ML algorithms you'll find six notebooks (06 - 11) showhing how to use Spark to implement the different ML algorithms.  `This is advanced level and only suitable for already experienced users - but feel free to look around.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run the workshop\n",
    "This workshop can be run online for free here ([launch](https://mybinder.org/v2/gh/hpe-container-platform-community/Apache-Spark-Tutorials/master?labpath=work/00_README_FIRST.ipynb)) - it may take about 5 mins to launch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback\n",
    "\n",
    "If after following this workshop you feel that the objectives haven't been achieved, please [email me](mailto:chris.snow@hpe.com) with your feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "You should have basic Python knowledge and be familiar with using Jupyter Notebooks.  If not, the following free hands-on workshops are recommended:\n",
    "\n",
    " - [Python 101](https://hackshack.hpedev.io/workshop/15)\n",
    " - [Jupyter Notebooks 101](https://hackshack.hpedev.io/workshop/25)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Notebook      | Description |\n",
    "| ----------- | ----------- |\n",
    "| [01 What is Apache Spark](./01_What_is_Apache_Spark.ipynb) | A description of what Spark is and what principles Spark is built on |\n",
    "| [02 Low Level APIs](./02_Low_Level_APIs.ipynb) | Understand the fundamental concept in spark called RDDs |\n",
    "| [03 Data Wrangling using RDDs](./03_Data_Wrangling_using_RDDs.ipynb) | Data Wrangling using RDDs |\n",
    "| [04 Structured APIs](./04_Structured_APIs.ipynb) | Structured APIs - RDDs vs DataFrames and Datasets |\n",
    "| [05 Exercise](./05_1_Exercise.ipynb) | Exercise - have fun |\n",
    "| [05 Solution](./05_2_Solution.ipynb) | Solution to the exercise |\n",
    "| This is the advanced section | ML based algorithms with Spark.|\n",
    "| [06 Linear Regression](./06_Linear_Regression.ipynb) | Linear Regression |\n",
    "| [07 Logistic Regression](./07_Logistic_Regression.ipynb) | Logistic Regression |\n",
    "| [08 Tree Based Models](./08_Tree_Based_Models.ipynb) | Tree Based Models |\n",
    "| [09 Clustering](./09_Clustering.ipynb) | Clustering |\n",
    "| [10 Recommender Systems](./10_Recommender_Systems.ipynb) | Recommender Systems |\n",
    "| [11 Natural Language Processing](./11_Natural_Language_Processing.ipynb) | Natural Language Processing |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options for running the workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**HPE DEV workshop environment**\n",
    "\n",
    "[hpe dev workshop](https://hackshack.hpedev.io/workshops) (TODO - replace final link when ready).\n",
    "\n",
    "If you try to run this workshop directly on your laptop you are likely to encounter errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you have a local environment with Docker**\n",
    "\n",
    " - on your laptop run `docker run -it -p 8888:8888 jupyter/pyspark-notebook:spark-3.2.1`\n",
    " - with your browser open the link output by the previous command\n",
    " - in jupyter open a terminal\n",
    " - run `git clone https://github.com/hpe-container-platform-community/Apache-Spark-Tutorials`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you have a local environment with Spark, Python (PySpark) and Jupyter**\n",
    "\n",
    " - run `git clone https://github.com/hpe-container-platform-community/Apache-Spark-Tutorials`\n",
    " - Start Jupyter and open this notebook\n",
    " - Make sure you have Spark and pyspark installed and configured\n",
    " - for the advanced section numpy and pandas has to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Navigation\n",
    "\n",
    "Click [Next](./01_What_is_Apache_Spark.ipynb) to start the workshop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Image](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1200px-Apache_Spark_logo.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains suggested solutions to the exercises. Since the exercises can be implemented in different ways and with different notations, the suggested solutions may differ from the code written in the exercise - that's totally ok :) But at least the output of the individual code cells should match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Create a SparkSession*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - let's create a *Spark session* - do you remenber which object you have to import?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkSession from library\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Exercise\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.178.62:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Exercise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10edce340>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display information about the Spark session\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Load data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need data to work with. For this we load data that is already provided in the local /data/berlin-data folder.<br><br>\n",
    "The data was downloaded from the repository: https://github.com/berlinonline/haeufige-vornamen-berlin.<br>\n",
    "The originator of the data in the original repository folder data/source/ is \"Berlin State Office for Citizens and Regulatory Affairs (LABO)\".<br>\n",
    "The originator of the 'cleaned' data in the original repository folder data/cleaned/ is the \"Berlin State Office for Citizens' and Regulatory Affairs (LABO) / BerlinOnline Stadtportal GmbH & Co. KG\".<br>\n",
    "\n",
    "All data sets contained in the repository are licensed under CC BY 3.0 DE (Creative Commons Attribution 3.0 Germany License)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data content and data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2013, the Berlin city data portal daten.berlin.de has always published lists of the first names of all newborn children and those registered with the registry office at the beginning of the new year. The State Office for Civil and Regulatory Affairs collects the lists from the registry offices in the individual Berlin districts and then publishes them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a folder for each year that contains a CSV file with the frequency of names for each district of Berlin.<br><br>\n",
    "For the years 2012-2016, the column structure of the CSV files is as follows:\n",
    "- 'vorname' specifies the first name\n",
    "- 'anzahl' the total number of children registered with this name\n",
    "- 'geschlecht' the gender of the child\n",
    "\n",
    "From 2017 there is an additional column 'position':\n",
    "- 'position': In the event that a child has been given several first names, position designates the position<br> of the name in the list of names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*There is nothing to add or exchange in the next code cell!*<br><br> In the next cell, all data in the different subdirectories is read, the information from folder names and file names is added to the datafarm as columns and all data is brought into a uniform schema. Furthermore, all column names and values are converted from German to English and the 'new' dataframe is saved as a file. The file is the basis for the further tasks in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# import lit function from library\n",
    "import os\n",
    "from pyspark.sql.functions import lit, translate\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "\n",
    "# create schema for dataframe\n",
    "csvSchema = StructType([StructField(\"vorname\", StringType(), True),\n",
    "                             StructField(\"anzahl\", IntegerType(), True),\n",
    "                             StructField(\"geschlecht\", StringType(), True),\n",
    "                             StructField(\"position\", IntegerType(), True),\n",
    "                             StructField(\"year\", IntegerType(), True),\n",
    "                             StructField(\"district\", StringType(), True) \n",
    "                            ])\n",
    "\n",
    "# create empty dataframe\n",
    "df = spark.createDataFrame(spark.sparkContext.emptyRDD(), csvSchema)\n",
    "\n",
    "# 'root' path of berlin data\n",
    "fileDirectory = 'data/berlin-data/cleaned/'\n",
    "# loop over all subdirectories (each subdir = one year of data)\n",
    "for dname in os.listdir(fileDirectory):    \n",
    "    # loop over all files in the 'year' directory\n",
    "    fpath = fileDirectory + dname + \"/\"\n",
    "    for fname in os.listdir(fpath):\n",
    "        df_tmp = spark.read.format(\"csv\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\",True)\\\n",
    "            .load(fpath + fname)\n",
    "        # check if schema contains row 'position'. if not add row with default value 1\n",
    "        if not (\"position\" in df_tmp.columns):\n",
    "                    df_tmp = df_tmp.withColumn(\"position\", lit(1))\n",
    "        # get the final component of a pathname. This represents the year.\n",
    "        year = os.path.basename(os.path.dirname(fpath))\n",
    "        # add the year value column\n",
    "        df_tmp = df_tmp.withColumn(\"Year\", lit(year))\n",
    "        # add the disrict value column. The district value is the file name without '.csv' extension.\n",
    "        df_tmp = df_tmp.withColumn(\"District\", lit(fname[:-4]))\n",
    "        # add the df_tmp dataframe to the df dataframe \n",
    "        df = df.union(df_tmp)\n",
    "\n",
    "# rename columns from German -> English\n",
    "df = df.withColumnRenamed(\"vorname\",\"FirstName\") \\\n",
    "    .withColumnRenamed(\"anzahl\",\"NumberOfChildren\")\\\n",
    "    .withColumnRenamed(\"geschlecht\",\"Gender\")\\\n",
    "    .withColumnRenamed(\"position\",\"Position\")\\\n",
    "    .withColumnRenamed(\"year\",\"Year\")\\\n",
    "    .withColumnRenamed(\"district\",\"District\")\n",
    "\n",
    "# change gender value from w (weiblich) -> f (female)    \n",
    "df = df.withColumn('Gender', translate('Gender', 'w', 'f'))\n",
    "# Write DataFrame data to CSV file\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"data/berlin-data/berlin-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - in the next cells you have to \n",
    "- read a file in csv format and create a dataframe\n",
    "- persist the dataframe with the default storage level (MEMORY_AND_DISK)\n",
    "- print the schema of the dataframe\n",
    "- display the number of rows in the dataframe\n",
    "- display the first ten rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read .csv file\n",
    "df = spark.read.format(\"csv\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\",True)\\\n",
    "            .load(\"data/berlin-data/berlin-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if dataframe is already cached - if not cache/persist the dataframe\n",
    "if not (df.storageLevel.useMemory) :\n",
    "    df.cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- NumberOfChildren: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Position: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the dataframe schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "310025"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the number of rows in the dataframe\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------+--------+----+-----------------+\n",
      "|FirstName|NumberOfChildren|Gender|Position|Year|District         |\n",
      "+---------+----------------+------+--------+----+-----------------+\n",
      "|Sophie   |27              |f     |1       |2013|treptow-koepenick|\n",
      "|Alexander|21              |m     |1       |2013|treptow-koepenick|\n",
      "|Charlotte|21              |f     |1       |2013|treptow-koepenick|\n",
      "|Marie    |21              |f     |1       |2013|treptow-koepenick|\n",
      "|Paul     |19              |m     |1       |2013|treptow-koepenick|\n",
      "|Jonas    |17              |m     |1       |2013|treptow-koepenick|\n",
      "|Anton    |13              |m     |1       |2013|treptow-koepenick|\n",
      "|Emilia   |13              |f     |1       |2013|treptow-koepenick|\n",
      "|Luca     |13              |m     |1       |2013|treptow-koepenick|\n",
      "|Mia      |13              |f     |1       |2013|treptow-koepenick|\n",
      "+---------+----------------+------+--------+----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the first ten rows of the dataframe\n",
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Analyse data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know how many rows are in the dataframe.<br><br>Exercise - let's find out \n",
    "- how many different first names do exist\n",
    "- how many female and male entries exist\n",
    "- how many entries are made for each year\n",
    "- what is the most popular female first name\n",
    "- what is the most popular male first name\n",
    "- the maximum number of first name in the register (maximum position)\n",
    "- which district has the most entries\n",
    "- How many children have the same name (NumberOfChildren) in average in the year 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT FirstName)|\n",
      "+-------------------------+\n",
      "|                    56478|\n",
      "+-------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56478"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many different first names do exist?\n",
    "\n",
    "# import countDistinct function from library\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"FirstName\")).show()\n",
    "\n",
    "# alternative implementation (return type is integer)\n",
    "df.select(\"FirstName\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Gender| count|\n",
      "+------+------+\n",
      "|     m|156627|\n",
      "|     f|153398|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how many different female and male entries exist?\n",
    "df.groupBy(\"Gender\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|count|\n",
      "+----+-----+\n",
      "|2015|27548|\n",
      "|2013|26070|\n",
      "|2014|27222|\n",
      "|2012|25971|\n",
      "|2017|35081|\n",
      "|2018|35176|\n",
      "|2019|34595|\n",
      "|2020|34620|\n",
      "|2021|34682|\n",
      "|2016|29060|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how many entries are made for each year?\n",
    "df.sort(\"Year\").groupBy(df.Year).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------+--------+----+--------------------------+\n",
      "|FirstName|NumberOfChildren|Gender|Position|Year|District                  |\n",
      "+---------+----------------+------+--------+----+--------------------------+\n",
      "|Marie    |128             |f     |1       |2015|pankow                    |\n",
      "|Marie    |122             |f     |1       |2014|pankow                    |\n",
      "|Marie    |122             |f     |1       |2012|charlottenburg-wilmersdorf|\n",
      "|Marie    |121             |f     |1       |2013|charlottenburg-wilmersdorf|\n",
      "|Marie    |119             |f     |1       |2013|pankow                    |\n",
      "+---------+----------------+------+--------+----+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the most popular female first name?\n",
    "df.sort(df.NumberOfChildren.desc()).filter(df.Gender == \"f\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------+--------+----+--------------------------+\n",
      "|FirstName|NumberOfChildren|Gender|Position|Year|District                  |\n",
      "+---------+----------------+------+--------+----+--------------------------+\n",
      "|Alexander|74              |m     |1       |2015|pankow                    |\n",
      "|Alexander|73              |m     |1       |2016|tempelhof-schoeneberg     |\n",
      "|Paul     |69              |m     |1       |2012|pankow                    |\n",
      "|Alexander|68              |m     |1       |2016|charlottenburg-wilmersdorf|\n",
      "|Alexander|68              |m     |1       |2016|pankow                    |\n",
      "+---------+----------------+------+--------+----+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the most popular female first name?\n",
    "df.sort(df.NumberOfChildren.desc()).filter(df.Gender == \"m\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max(Position)|\n",
      "+-------------+\n",
      "|            8|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the maximum number of first names somebody has (maximum position)?\n",
    "\n",
    "# import max function from library\n",
    "from pyspark.sql.functions import max\n",
    "df.select(max(\"Position\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+\n",
      "|District                  |count|\n",
      "+--------------------------+-----+\n",
      "|mitte                     |41670|\n",
      "|tempelhof-schoeneberg     |40136|\n",
      "|charlottenburg-wilmersdorf|38062|\n",
      "|friedrichshain-kreuzberg  |36778|\n",
      "|pankow                    |29550|\n",
      "|spandau                   |27970|\n",
      "|neukoelln                 |27510|\n",
      "|lichtenberg               |22726|\n",
      "|treptow-koepenick         |12184|\n",
      "|reinickendorf             |11811|\n",
      "|steglitz-zehlendorf       |11127|\n",
      "|marzahn-hellersdorf       |10497|\n",
      "|standesamt_i              |4    |\n",
      "+--------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# which district has the most entries?\n",
    "\n",
    "# import functions from library\n",
    "from pyspark.sql.functions import col\n",
    "df.groupBy(\"District\").count().sort(col(\"count\").desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|avg(NumberOfChildren)|\n",
      "+---------------------+\n",
      "|   1.8687503604175077|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many children have the same name (NumberOfChildren) in average in the year 2021?\n",
    "\n",
    "# import functions from library\n",
    "from pyspark.sql.functions import avg\n",
    "df.filter(df.Year == '2021').agg(avg(\"NumberOfChildren\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Analyse data using 'sql' and 'join' commands*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside the functions used in above chapter we know want to use 'join' commands.<br><br>\n",
    "Exercise - let's find out \n",
    "- how many first names exist in dictrict mitte but not in district pankow\n",
    "- how many female and male entries exist\n",
    "- how many entries are made for each year\n",
    "- what is the most popular female first name\n",
    "- what is the most popular male first name\n",
    "- the maximum number of first name in the register (maximum position)\n",
    "- which district has the most entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to have 'easier' acces to the different data of the districts \n",
    "# we can create new dataframe for the relevant districts\n",
    "\n",
    "df_mitte = df.filter(df.District == 'mitte')\n",
    "df_pankow = df.filter(df.District == 'pankow')\n",
    "df_lichtenberg = df.filter(df.District == 'lichtenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15898"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many first names exist in dictrict mitte but not in district pankow? \n",
    "# use dataframe 'join' command\n",
    "\n",
    "df_mitte.join(df_pankow, (df_mitte.FirstName == df_pankow.FirstName), \"leftanti\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|15898   |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how many first names exist in dictrict mitte but not in district pankow? \n",
    "# use 'sql' command - hint: don't forget to create local temporary views\n",
    "\n",
    "df_mitte.createOrReplaceTempView(\"mitte\")\n",
    "df_pankow.createOrReplaceTempView(\"pankow\")\n",
    "\n",
    "joinDF = spark.sql(\"SELECT count(*) FROM mitte m \\\n",
    "                    LEFT OUTER JOIN pankow p \\\n",
    "                    ON m.FirstName = p.FirstName \\\n",
    "                    WHERE p.FirstName IS NULL \") \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop The Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the underlying SparkContext.\n",
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    print(\"Spark session does not context exist - nothing to stop.\")\n",
    "else:\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*This is the end of the Spark101 course. The next notebooks show ML algorithms with Spark - for advanced users.*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
